# LLM 모델 업그레이드가 문서 가이드에 미치는 영향 분석

> 이 문서는 SOFA 시스템의 LLM 모델을 업그레이드할 때 고객사 문서 작성 가이드의 변경 필요성을 분석한 결과입니다.

---

## 결론 요약

**문서 준비 가이드는 LLM 모델이 아닌 RAG 파이프라인 구조에 의해 결정됩니다.**

단순히 챗봇 응답 생성에 사용하는 LLM(Gemini, GPT, Claude 등)을 업그레이드해도 고객이 준비해야 할 문서 형식은 **동일하게 유지**됩니다.

---

## 1. 모델 변경과 무관한 요소 (가이드 유지)

다음 요소들은 코드에 구현되어 있으며, LLM 모델과 독립적으로 동작합니다.

| 요소 | 구현 위치 | 설명 |
|------|----------|------|
| **청킹 로직** | `lib/rag/chunking.ts` | 500자 최대, 50자 오버랩 - 하드코딩 |
| **Q&A 패턴 인식** | `lib/rag/chunking.ts` | 정규식 기반 패턴 매칭 |
| **품질 점수 산정** | `lib/rag/chunking.ts` | 알고리즘 기반 점수 계산 |
| **Hybrid Search** | `lib/rag/retrieval.ts` | 임베딩 + BM25 검색 |
| **파일 형식 지원** | `lib/parsers/*` | 파서 구현 기반 |

### 청킹 설정 (코드 기준)

```typescript
// lib/rag/chunking.ts
const DEFAULT_OPTIONS: ChunkOptions = {
  maxChunkSize: 500,      // 최대 청크 크기
  overlap: 50,            // 오버랩
  preserveStructure: true // 구조 보존
};
```

### Q&A 패턴 인식 (코드 기준)

```typescript
// lib/rag/chunking.ts
const qaPattern = /((?:Q|질문|문)[:：][^\n]+(?:\n(?:A|답변|답)[:：][^\n]+)+)/gi;
```

### 품질 점수 산정 (코드 기준)

```typescript
// lib/rag/chunking.ts - calculateQualityScore()
// 기본 100점에서 시작
// 감점: 100자 미만(-20), 800자 초과(-10), 문장 미완성(-15), 불완전 Q&A(-30), 의미없는 문자(-25)
// 가산점: Q&A 쌍(+10), 헤더 포함(+5)
```

---

## 2. 모델 변경 시 달라질 수 있는 요소

이론적으로 다음 요소들은 모델 성능에 따라 달라질 수 있습니다.

| 요소 | 현재 상태 | 고성능 모델 적용 시 |
|------|----------|-------------------|
| **컨텍스트 윈도우** | 제한적 (청크 3-5개) | 더 많은 청크 활용 가능 |
| **긴 문서 처리** | 500자 분할 필수 | 100K+ 컨텍스트 → 청킹 덜 중요해질 수 있음 |
| **복잡한 추론** | 단순 Q&A 최적 | 복잡한 관계/맥락 추론 가능 |
| **다국어 처리** | 한국어/영어 최적화 | 더 다양한 언어 지원 가능 |

### 주의사항

위 변화가 실제로 적용되려면 **코드 수정이 필요**합니다. 모델만 교체한다고 자동으로 바뀌지 않습니다.

---

## 3. 가이드 변경이 필요한 시점

### 3.1 코드 변경이 있을 때만

| 변경 유형 | 가이드 영향 | 필요 조치 |
|----------|------------|----------|
| **LLM 모델만 교체** (GPT → Claude) | ❌ 영향 없음 | 없음 |
| **임베딩 모델 교체** | ⚠️ 미미한 영향 | 최적 길이 재검토 |
| **청킹 알고리즘 수정** | ✅ 가이드 업데이트 필요 | 길이 권장사항 수정 |
| **Q&A 패턴 추가** | ✅ 가이드 업데이트 필요 | 새 패턴 안내 추가 |
| **품질 점수 공식 변경** | ✅ 가이드 업데이트 필요 | 점수 산정 섹션 수정 |
| **RAG 아키텍처 변경** | ✅ 가이드 전면 수정 필요 | 전체 재작성 |

### 3.2 구체적인 코드 변경 예시

**예시 1: 청킹 크기 변경**
```typescript
// 변경 전
const DEFAULT_OPTIONS = { maxChunkSize: 500, overlap: 50 };

// 변경 후
const DEFAULT_OPTIONS = { maxChunkSize: 1000, overlap: 100 };
```
→ 가이드의 "100-500자 권장" → "200-1000자 권장"으로 수정 필요

**예시 2: 새 Q&A 패턴 추가**
```typescript
// 기존
/(Q|질문|문)[:：].*\n(A|답변|답)[:：].*/

// 추가
/(FAQ|자주묻는질문)[:：].*\n(답변|해결)[:：].*/
```
→ 가이드에 새 패턴 형식 안내 추가 필요

---

## 4. 현재 시스템 아키텍처

```
┌─────────────────────────────────────────────────────────────┐
│                    문서 준비 가이드 영향 범위                    │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │   문서 업로드  │ → │   스마트 청킹  │ → │   임베딩 생성  │     │
│  │  (파서 처리)  │    │  (500자/50자) │    │  (OpenAI)   │     │
│  └─────────────┘    └─────────────┘    └─────────────┘     │
│         ↑                  ↑                  ↑            │
│         │                  │                  │            │
│    코드 변경 시          코드 변경 시         모델 변경 시       │
│    가이드 수정           가이드 수정         영향 미미         │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                    문서 준비 가이드 영향 외                     │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │  Hybrid     │ → │  Query      │ → │  LLM 응답    │     │
│  │  Search     │    │  Rewriting  │    │  생성       │     │
│  └─────────────┘    └─────────────┘    └─────────────┘     │
│                                               ↑            │
│                                               │            │
│                                    모델 업그레이드 영역       │
│                                    (가이드 영향 없음)        │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 5. 권장 사항

### 5.1 모델 업그레이드 시 체크리스트

- [ ] 청킹 설정 변경 여부 확인
- [ ] 임베딩 모델 변경 여부 확인
- [ ] Q&A 패턴 추가 여부 확인
- [ ] 품질 점수 공식 변경 여부 확인

### 5.2 가이드 업데이트 워크플로우

```
코드 변경 발생
     ↓
해당 변경이 문서 처리 파이프라인에 영향을 미치는가?
     ↓
  Yes → 가이드 업데이트 필요
  No  → 가이드 유지
```

### 5.3 버전 관리

가이드 문서에 시스템 버전을 명시하여 추적:

```markdown
*이 가이드는 SOFA 시스템 v1.0 기준으로 작성되었습니다.*
```

---

## 6. 관련 파일 참조

| 파일 | 역할 |
|------|------|
| [lib/rag/chunking.ts](../lib/rag/chunking.ts) | 청킹 알고리즘, 품질 점수 |
| [lib/rag/retrieval.ts](../lib/rag/retrieval.ts) | Hybrid Search |
| [lib/rag/embedding.ts](../lib/rag/embedding.ts) | 임베딩 생성 |
| [lib/rag/generator.ts](../lib/rag/generator.ts) | LLM 응답 생성 |
| [docs/document-preparation-guide.md](./document-preparation-guide.md) | 고객사 문서 가이드 |

---

*작성일: 2025-12-31*
*분석 기준: SOFA 시스템 현재 코드베이스*
