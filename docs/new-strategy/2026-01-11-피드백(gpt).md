# RAG 문서 재구성 + 검수(Approval) 워크플로우 정리

> 목표: 사용자가 업로드한 문서를 **RAG에 더 잘 걸리는 형태로 재구성**하되, 환각/누락/오분류 리스크를 **검수 가능한 UX**로 통제한다.

---

## 1) 문제 정의 (Why)

### 현재 겪는 문제
- “의미 단위 청킹”만으로는 **문서 구조가 깨진 상태**를 복원하기 어렵다.
- 특히 PDF/레이아웃 문서에서 아래 문제가 반복됨:
  - 헤더(부서명)와 콘텐츠(연락처)가 페이지/줄바꿈/공백으로 분리
  - 표/리스트가 깨져서 항목이 “독립 청크”로 잘못 저장
  - 헤더 경로(header path)를 잃어 **컨텍스트 연결 실패**

### 결과
- RAG에서 검색/답변 시 “정확한 단위로 묶여야 할 지식(예: 마케팅팀 연락처 30개)”이
  - 10개씩 쪼개져 저장되거나,
  - 헤더 없이 떠돌아다니는 데이터가 됨.

---

## 2) 핵심 아이디어

### 문서 재구성(Restructuring) + 검수(Approval)로 전환
- LLM을 “그냥 청킹”이 아니라 **구조 복원/정규화 엔진**으로 사용
- 단, 자동 학습이 아니라 **반자동(사용자 검수/수정/승인)** 워크플로우로 설계
- 검수는 전수검사가 아니라 **의심 항목만** 보도록 축소(검수 피로 방지)

---

## 3) 접근 옵션(Trade-offs)

### A. 규칙/레이아웃 기반 구조 복원 후 청킹
- 장점: 비용 낮고 환각 없음
- 단점: 문서 포맷 다양할수록 규칙이 폭증(유지보수 지옥)

### B. LLM 기반 “문서 → 지식 유닛” 재구성
- 장점: 헤더 단절/표 깨짐/레이아웃 문제에 강함
- 단점: 비용↑, 복잡↑, **근거 추적 없으면 신뢰도 급락**

### C. 하이브리드(권장): 원문 청크 + 재구성 청크 2레벨 인덱스
- 탐색은 “정리본(재구성본)”으로 빠르게
- 근거는 “원문”으로 확실하게
- 가장 안전하고 실무적으로 디버깅/감사에 유리

---

## 4) 중요한 실무 원칙(필수)

1. **원문은 절대 버리지 않는다** (감사/법적/디버깅)
2. 재구성 결과는 반드시 **근거(provenance)** 를 가진다  
   - 페이지/라인/오프셋/스니펫 등
3. **추정 금지**: 근거 없으면 `Unknown / NOT_FOUND`로 둔다
4. 목표는 요약이 아니라 **정규화 + 구조화**  
   - 같은 사실을 반복/확장하지 않는다(토큰 낭비 방지)
5. **평가 루프**를 둔다  
   - 누락률, 오분류, 잘못된 귀속률 등

---

## 5) 실패 시나리오(Devil’s Advocate)

1) 사용자가 결국 검수하지 않음  
- 해결: 전수검수 금지 → **High-risk만 필수** + 상위 5~10개만 노출

2) LLM 환각으로 잘못된 구조 생성  
- 해결: 스키마 강제 + 추정 금지 + 근거 스팬 요구

3) 업데이트가 잦아 재처리 비용 폭발  
- 해결: 해시 기반 캐시, 변경 구간만 부분 재처리

4) 보안/민감정보 노출 위험 증가  
- 재구성본이 더 읽기 쉬워져 노출이 쉬워짐  
- 해결: 마스킹 옵션(이메일/전화/주민번호 등) + 권한/감사 로그

---

## 6) 검수 UX 제안: “좌 원본 / 우 재구성(MD) + 의심 항목”

### 핵심 UX 포인트
- 스크롤 동기화보다 중요한 것은 **근거 점프(클릭 → 원문 위치로 이동)**
- 단순 side-by-side는 검수 피로가 높으므로
  - “차이점만 보기(Added/Missing/Moved)”는 Phase 2에서
  - Phase 1은 “의심 항목 5~10개”로 최소화

### 문서2 관점(추가)
- 사용자는 승인/거부만이 아니라 **직접 수정 가능한 에디터**가 필요
- “사용자가 고친 데이터”가 가장 품질이 좋음

---

## 7) 통합 권장안(Phase Roadmap)

### Phase 1 (2주 내 MVP 목표)
- 좌: 원본 PDF 뷰어
- 우: 마크다운 에디터(수정 가능)
- AI 생성 **의심 항목 리스트(5~10개)**  
  - 숫자/연락처/날짜 불일치, 누락, 헤더-콘텐츠 연결 실패
- 항목 클릭 → 원문 페이지로 점프(페이지+스니펫 기반)
- [승인] → 청킹/인덱싱 진행

### Phase 2 (검증 후 확장)
- Added/Missing/Contradicted 필터
- Claim 단위 검증 리포트(구조화)
- 감사 로그(Audit)

### Phase 3 (고객 피드백 기반)
- 스크롤 동기화
- 민감정보 마스킹 강화
- 버전 관리(재구성본 히스토리)

---

## 8) “의심 항목 추출” 설계 (Phase 1의 핵심)

### 권장: 규칙 + LLM 하이브리드
1) 규칙 기반 엔티티 추출
- 이메일/전화/날짜/숫자 패턴

2) 규칙 기반 mismatch 후보 생성
- 재구성본에만 있음(Added)
- 원문에만 있음(Missing)
- 값 변경(Contradicted)
- 헤더 연결 불명확(HEADER_LINK)

3) LLM은 “검수 카드” 생성에 사용
- 왜 의심인지, 근거는 어디인지, 사용자가 뭘 수정해야 하는지 설명

### 판정 체계(3값)
- `SUPPORTED` / `CONTRADICTED` / `NOT_FOUND`

---

## 9) 의심 항목 생성 프롬프트(샘플, JSON 출력)

> 입력:
- `original_pages`: [{page, text}]
- `reconstructed_md`: string

```text
역할: 당신은 '문서 재구성 검수 도우미'다. 목표는 사용자가 빠르게 검수할 수 있도록 '의심 항목'만 5~10개로 추려서 리포트하는 것이다.

중요 규칙:
- 추정/보간 금지. 원문에 근거가 없는 내용은 "NOT_FOUND"로 표시하고 만들어내지 마라.
- 의심 항목은 아래 타입만 다룬다: CONTACT(전화/이메일), DATE, NUMBER, HEADER_LINK(헤더-콘텐츠 연결), MISSING_ITEM(원문 누락)
- 출력은 반드시 JSON 배열로만 출력한다. 설명 문장 금지.

입력:
1) original_pages: (페이지별 원문 텍스트)
2) reconstructed_md: (재구성된 마크다운)

해야 할 일:
- reconstructed_md의 각 항목/문장에서 검증 가능한 값(연락처/날짜/숫자)을 찾아라.
- 각 값에 대해 original_pages에서 근거로 볼 수 있는 텍스트 스니펫을 1~3개 찾아라.
- 다음 중 하나로 판정하라: SUPPORTED / CONTRADICTED / NOT_FOUND
- 그리고 '사용자가 무엇을 확인/수정해야 하는지'를 한 줄로 제안하라.
- 의심도가 높은 것부터 최대 10개만 출력하라.

JSON 스키마:
[
  {
    "id": "S1",
    "severity": "HIGH|MED|LOW",
    "type": "CONTACT|DATE|NUMBER|HEADER_LINK|MISSING_ITEM",
    "claim": "재구성본에서 주장/기재된 값(짧게)",
    "md_anchor": "재구성본에서 위치를 찾기 위한 짧은 앵커(예: 헤더명/인접 문장 일부)",
    "verdict": "SUPPORTED|CONTRADICTED|NOT_FOUND",
    "evidence": [
      {"page": 3, "snippet": "원문 스니펫(최대 200자)"},
      {"page": 4, "snippet": "..." }
    ],
    "reason": "왜 의심인지(최대 120자)",
    "suggested_action": "사용자가 할 행동(예: '원문에 근거 없으면 부서명을 제거/수정')"
  }
]