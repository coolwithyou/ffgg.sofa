/**
 * ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬ ìŠ¤í¬ë¦½íŠ¸
 *
 * ì²­í¬ì™€ ë¬¸ì„œì˜ ë°ì´í„° ì¼ê´€ì„±ì„ ê²€ì‚¬í•˜ê³  ë¬¸ì œì ì„ ë³´ê³ í•©ë‹ˆë‹¤.
 *
 * ì‚¬ìš©ë²•:
 *   pnpm exec dotenv -e .env.local -- npx tsx scripts/check-data-integrity.ts
 *   pnpm exec dotenv -e .env.local -- npx tsx scripts/check-data-integrity.ts --fix
 *
 * ê²€ì‚¬ í•­ëª©:
 *   1. chunks.datasetIdì™€ documents.datasetId ë¶ˆì¼ì¹˜
 *   2. chunks.datasetIdê°€ nullì¸ í•­ëª© (ê²€ìƒ‰ ë¶ˆê°€)
 *   3. embeddingì´ nullì¸ ì²­í¬ (Dense ê²€ìƒ‰ ë¶ˆê°€)
 *   4. statusê°€ 'approved'ê°€ ì•„ë‹Œ í™œì„± ì²­í¬
 *   5. orphan ì²­í¬ (documentê°€ ì‚­ì œëœ ì²­í¬)
 */

import { db } from '../lib/db';
import { documents, chunks, datasets } from '../drizzle/schema';
import { eq, sql, isNull, and, ne } from 'drizzle-orm';

interface IntegrityIssue {
  type: string;
  count: number;
  samples: Array<{
    chunkId: string;
    documentId: string;
    details: string;
  }>;
}

async function checkDataIntegrity(fixIssues: boolean = false) {
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('              ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬ ì‹œì‘');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

  const issues: IntegrityIssue[] = [];

  // 1. chunks.datasetIdì™€ documents.datasetId ë¶ˆì¼ì¹˜ ê²€ì‚¬
  console.log('ğŸ” [1/5] datasetId ë¶ˆì¼ì¹˜ ê²€ì‚¬...');
  const mismatchedChunks = await db.execute(sql`
    SELECT
      c.id as chunk_id,
      c.document_id,
      c.dataset_id as chunk_dataset_id,
      d.dataset_id as doc_dataset_id,
      LEFT(c.content, 50) as content_preview
    FROM chunks c
    INNER JOIN documents d ON c.document_id = d.id
    WHERE c.dataset_id IS DISTINCT FROM d.dataset_id
    LIMIT 10
  `);

  const [mismatchCount] = await db.execute(sql`
    SELECT COUNT(*)::int as count
    FROM chunks c
    INNER JOIN documents d ON c.document_id = d.id
    WHERE c.dataset_id IS DISTINCT FROM d.dataset_id
  `);

  if ((mismatchCount as any).count > 0) {
    issues.push({
      type: 'datasetId ë¶ˆì¼ì¹˜',
      count: (mismatchCount as any).count,
      samples: (mismatchedChunks.rows as any[]).map((r) => ({
        chunkId: r.chunk_id,
        documentId: r.document_id,
        details: `ì²­í¬: ${r.chunk_dataset_id || 'null'} â‰  ë¬¸ì„œ: ${r.doc_dataset_id || 'null'}`,
      })),
    });
    console.log(`   âŒ ${(mismatchCount as any).count}ê°œ ë¶ˆì¼ì¹˜ ë°œê²¬`);

    if (fixIssues) {
      console.log('   ğŸ”§ ìë™ ìˆ˜ì • ì¤‘...');
      await db.execute(sql`
        UPDATE chunks c
        SET dataset_id = d.dataset_id, updated_at = NOW()
        FROM documents d
        WHERE c.document_id = d.id
        AND c.dataset_id IS DISTINCT FROM d.dataset_id
      `);
      console.log('   âœ… ìˆ˜ì • ì™„ë£Œ');
    }
  } else {
    console.log('   âœ… ë¶ˆì¼ì¹˜ ì—†ìŒ');
  }

  // 2. datasetIdê°€ nullì¸ ì²­í¬ ê²€ì‚¬
  console.log('\nğŸ” [2/5] datasetId null ê²€ì‚¬...');
  const nullDatasetChunks = await db.execute(sql`
    SELECT
      c.id as chunk_id,
      c.document_id,
      c.status,
      c.is_active,
      d.dataset_id as doc_dataset_id,
      LEFT(c.content, 50) as content_preview
    FROM chunks c
    LEFT JOIN documents d ON c.document_id = d.id
    WHERE c.dataset_id IS NULL
    AND c.is_active = true
    LIMIT 10
  `);

  const [nullDatasetCount] = await db.execute(sql`
    SELECT COUNT(*)::int as count
    FROM chunks c
    WHERE c.dataset_id IS NULL
    AND c.is_active = true
  `);

  if ((nullDatasetCount as any).count > 0) {
    issues.push({
      type: 'datasetId null (ê²€ìƒ‰ ë¶ˆê°€)',
      count: (nullDatasetCount as any).count,
      samples: (nullDatasetChunks.rows as any[]).map((r) => ({
        chunkId: r.chunk_id,
        documentId: r.document_id,
        details: `ë¬¸ì„œ datasetId: ${r.doc_dataset_id || 'null'}, ìƒíƒœ: ${r.status}`,
      })),
    });
    console.log(`   âŒ ${(nullDatasetCount as any).count}ê°œ ë°œê²¬ (ê²€ìƒ‰ì—ì„œ ì œì™¸ë¨)`);

    if (fixIssues) {
      console.log('   ğŸ”§ ìë™ ìˆ˜ì • ì¤‘ (documents í…Œì´ë¸”ì—ì„œ datasetId ë™ê¸°í™”)...');
      await db.execute(sql`
        UPDATE chunks c
        SET dataset_id = d.dataset_id, updated_at = NOW()
        FROM documents d
        WHERE c.document_id = d.id
        AND c.dataset_id IS NULL
        AND d.dataset_id IS NOT NULL
      `);
      console.log('   âœ… ìˆ˜ì • ì™„ë£Œ');
    }
  } else {
    console.log('   âœ… ë¬¸ì œ ì—†ìŒ');
  }

  // 3. embeddingì´ nullì¸ ì²­í¬ ê²€ì‚¬
  console.log('\nğŸ” [3/5] embedding null ê²€ì‚¬...');
  const [nullEmbeddingCount] = await db.execute(sql`
    SELECT COUNT(*)::int as count
    FROM chunks
    WHERE embedding IS NULL
    AND is_active = true
  `);

  if ((nullEmbeddingCount as any).count > 0) {
    const nullEmbeddingChunks = await db.execute(sql`
      SELECT id as chunk_id, document_id, status, LEFT(content, 50) as content_preview
      FROM chunks
      WHERE embedding IS NULL
      AND is_active = true
      LIMIT 10
    `);

    issues.push({
      type: 'embedding null (Dense ê²€ìƒ‰ ë¶ˆê°€)',
      count: (nullEmbeddingCount as any).count,
      samples: (nullEmbeddingChunks.rows as any[]).map((r) => ({
        chunkId: r.chunk_id,
        documentId: r.document_id,
        details: `ìƒíƒœ: ${r.status}, ë‚´ìš©: ${r.content_preview}...`,
      })),
    });
    console.log(`   âš ï¸ ${(nullEmbeddingCount as any).count}ê°œ ë°œê²¬ (Dense ê²€ìƒ‰ ë¶ˆê°€)`);
    console.log('   ğŸ’¡ ìˆ˜ì •: í•´ë‹¹ ë¬¸ì„œ ì¬ì²˜ë¦¬ í•„ìš” (scripts/reprocess-documents.ts)');
  } else {
    console.log('   âœ… ë¬¸ì œ ì—†ìŒ');
  }

  // 4. ë¹„í™œì„± ìƒíƒœì¸ë° is_active=trueì¸ ì²­í¬ ê²€ì‚¬
  console.log('\nğŸ” [4/5] ìƒíƒœ ë¶ˆì¼ì¹˜ ê²€ì‚¬...');
  const [statusMismatchCount] = await db.execute(sql`
    SELECT COUNT(*)::int as count
    FROM chunks
    WHERE status != 'approved'
    AND is_active = true
    AND dataset_id IS NOT NULL
  `);

  if ((statusMismatchCount as any).count > 0) {
    const statusMismatchChunks = await db.execute(sql`
      SELECT id as chunk_id, document_id, status, LEFT(content, 50) as content_preview
      FROM chunks
      WHERE status != 'approved'
      AND is_active = true
      AND dataset_id IS NOT NULL
      LIMIT 10
    `);

    issues.push({
      type: 'ìƒíƒœ ë¶ˆì¼ì¹˜ (ë¯¸ìŠ¹ì¸ í™œì„± ì²­í¬)',
      count: (statusMismatchCount as any).count,
      samples: (statusMismatchChunks.rows as any[]).map((r) => ({
        chunkId: r.chunk_id,
        documentId: r.document_id,
        details: `ìƒíƒœ: ${r.status}`,
      })),
    });
    console.log(`   âš ï¸ ${(statusMismatchCount as any).count}ê°œ ë°œê²¬ (ìŠ¹ì¸ í•„ìš”)`);
  } else {
    console.log('   âœ… ë¬¸ì œ ì—†ìŒ');
  }

  // 5. Orphan ì²­í¬ ê²€ì‚¬ (documentê°€ ì‚­ì œë¨)
  console.log('\nğŸ” [5/5] Orphan ì²­í¬ ê²€ì‚¬...');
  const [orphanCount] = await db.execute(sql`
    SELECT COUNT(*)::int as count
    FROM chunks c
    LEFT JOIN documents d ON c.document_id = d.id
    WHERE d.id IS NULL
  `);

  if ((orphanCount as any).count > 0) {
    const orphanChunks = await db.execute(sql`
      SELECT c.id as chunk_id, c.document_id, LEFT(c.content, 50) as content_preview
      FROM chunks c
      LEFT JOIN documents d ON c.document_id = d.id
      WHERE d.id IS NULL
      LIMIT 10
    `);

    issues.push({
      type: 'Orphan ì²­í¬ (ë¬¸ì„œ ì‚­ì œë¨)',
      count: (orphanCount as any).count,
      samples: (orphanChunks.rows as any[]).map((r) => ({
        chunkId: r.chunk_id,
        documentId: r.document_id,
        details: `ë¬¸ì„œê°€ ì‚­ì œë¨`,
      })),
    });
    console.log(`   âš ï¸ ${(orphanCount as any).count}ê°œ ë°œê²¬`);

    if (fixIssues) {
      console.log('   ğŸ”§ Orphan ì²­í¬ ì‚­ì œ ì¤‘...');
      await db.execute(sql`
        DELETE FROM chunks c
        WHERE NOT EXISTS (
          SELECT 1 FROM documents d WHERE d.id = c.document_id
        )
      `);
      console.log('   âœ… ì‚­ì œ ì™„ë£Œ');
    }
  } else {
    console.log('   âœ… ë¬¸ì œ ì—†ìŒ');
  }

  // ê²°ê³¼ ìš”ì•½
  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('                      ê²€ì‚¬ ê²°ê³¼ ìš”ì•½');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

  if (issues.length === 0) {
    console.log('âœ… ëª¨ë“  ê²€ì‚¬ í†µê³¼! ë°ì´í„° ë¬´ê²°ì„±ì— ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.\n');
  } else {
    console.log(`âŒ ${issues.length}ê°œ ìœ í˜•ì˜ ë¬¸ì œ ë°œê²¬:\n`);

    for (const issue of issues) {
      console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`);
      console.log(`ğŸ”¸ ${issue.type}`);
      console.log(`   ì´ ${issue.count}ê±´`);
      console.log(`   ìƒ˜í”Œ (ìµœëŒ€ 10ê°œ):`);
      for (const sample of issue.samples.slice(0, 5)) {
        console.log(`   - [${sample.chunkId.substring(0, 8)}...] ${sample.details}`);
      }
    }

    if (!fixIssues) {
      console.log('\nğŸ’¡ ìë™ ìˆ˜ì •ì„ ì›í•˜ì‹œë©´ --fix ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”:');
      console.log('   pnpm exec dotenv -e .env.local -- npx tsx scripts/check-data-integrity.ts --fix\n');
    }
  }

  // ì „ì²´ í†µê³„
  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('                      ì „ì²´ í†µê³„');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

  const [totalStats] = await db.execute(sql`
    SELECT
      (SELECT COUNT(*)::int FROM documents) as total_documents,
      (SELECT COUNT(*)::int FROM chunks) as total_chunks,
      (SELECT COUNT(*)::int FROM chunks WHERE is_active = true) as active_chunks,
      (SELECT COUNT(*)::int FROM chunks WHERE status = 'approved') as approved_chunks,
      (SELECT COUNT(*)::int FROM chunks WHERE dataset_id IS NOT NULL) as searchable_chunks,
      (SELECT COUNT(*)::int FROM datasets) as total_datasets
  `);

  const stats = totalStats as any;
  console.log(`ğŸ“Š ë¬¸ì„œ: ${stats.total_documents}ê°œ`);
  console.log(`ğŸ“Š ì²­í¬: ${stats.total_chunks}ê°œ (í™œì„±: ${stats.active_chunks})`);
  console.log(`ğŸ“Š ìŠ¹ì¸ëœ ì²­í¬: ${stats.approved_chunks}ê°œ`);
  console.log(`ğŸ“Š ê²€ìƒ‰ ê°€ëŠ¥ ì²­í¬: ${stats.searchable_chunks}ê°œ`);
  console.log(`ğŸ“Š ë°ì´í„°ì…‹: ${stats.total_datasets}ê°œ\n`);

  process.exit(issues.length > 0 && !fixIssues ? 1 : 0);
}

// CLI ì¸ì ì²˜ë¦¬
const fixIssues = process.argv.includes('--fix');
checkDataIntegrity(fixIssues).catch((e) => {
  console.error('ì˜¤ë¥˜ ë°œìƒ:', e);
  process.exit(1);
});
